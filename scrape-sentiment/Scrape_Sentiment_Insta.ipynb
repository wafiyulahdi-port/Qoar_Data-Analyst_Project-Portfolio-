{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b354a085",
   "metadata": {},
   "source": [
    "# SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117a3cd",
   "metadata": {},
   "source": [
    "## User Profile Scrape using Instaloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff7f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install instaloader\n",
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instaloader\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340da3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = instaloader.Instaloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"ahd.iiy\"\n",
    "PASSWORD = \"M.Wafiyulahdi123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    loader.load_session_from_file(USERNAME)\n",
    "    print(\"‚úÖ Sesi login berhasil dimuat.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"üîê Tidak ditemukan sesi login, melakukan login manual...\")\n",
    "    loader.login(USERNAME, PASSWORD)\n",
    "    loader.save_session_to_file()\n",
    "    print(\"‚úÖ Login berhasil dan sesi disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = df_comment['comment_user'].dropna().unique()\n",
    "user_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uname in usernames:\n",
    "    # Hapus '@' dari username\n",
    "    username_clean = uname.replace(\"@\", \"\").strip()\n",
    "    \n",
    "    try:\n",
    "        profile = instaloader.Profile.from_username(loader.context, username_clean)\n",
    "        user_info = {\n",
    "            \"username\": uname,\n",
    "            \"full_name\": profile.full_name,\n",
    "            \"followers\": profile.followers,\n",
    "            \"followees\": profile.followees,\n",
    "            \"is_private\": profile.is_private,\n",
    "            \"is_verified\": profile.is_verified,\n",
    "            \"bio\": profile.biography,\n",
    "            \"post_count\": profile.mediacount\n",
    "        }\n",
    "        user_data.append(user_info)\n",
    "        print(f\"‚úÖ Data {username_clean} berhasil diambil.\")\n",
    "        time.sleep(3)  # jeda agar tidak rate-limited\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Gagal mengambil data {username_clean}: {e}\")\n",
    "        user_data.append({\n",
    "            \"username\": uname,\n",
    "            \"full_name\": None,\n",
    "            \"followers\": None,\n",
    "            \"followees\": None,\n",
    "            \"is_private\": None,\n",
    "            \"is_verified\": None,\n",
    "            \"bio\": None,\n",
    "            \"post_count\": None\n",
    "        })\n",
    "\n",
    "# 4. Buat DataFrame hasil scraping user\n",
    "df_users = pd.DataFrame(user_data)\n",
    "df_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47361d95",
   "metadata": {},
   "source": [
    "## Post and Comment Scrappe using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a16555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf620fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil semua link postingan\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--log-level=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a91d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Login ke Instagram\n",
    "driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "time.sleep(5)\n",
    "\n",
    "username = \"username\"\n",
    "password = \"pass\"\n",
    "\n",
    "driver.find_element(By.NAME, \"username\").send_keys(username)\n",
    "driver.find_element(By.NAME, \"password\").send_keys(password)\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "time.sleep(10)\n",
    "\n",
    "# Buka profil target\n",
    "target_username = \"yumboxindonesia\"\n",
    "base_url = f\"https://www.instagram.com/{target_username}/\"\n",
    "driver.get(base_url)\n",
    "time.sleep(10)\n",
    "\n",
    "# Scroll untuk memuat semua post\n",
    "SCROLL_PAUSE_TIME = 20\n",
    "NUM_SCROLLS = 10\n",
    "for _ in range(NUM_SCROLLS):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "# Ambil semua link post unik\n",
    "post_links = driver.find_elements(By.XPATH, '//a[contains(@href, \"/p/\")]')\n",
    "post_urls = list(set(link.get_attribute('href') for link in post_links if link.get_attribute('href')))\n",
    "\n",
    "# Simpan link ke file\n",
    "with open(\"data_link_post.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for url in post_urls:\n",
    "        f.write(url + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ {len(post_urls)} link berhasil disimpan di data_link_post.txt.\")\n",
    "\n",
    "# Tahap 2: Ambil caption dan komentar dari tiap postingan\n",
    "with open(\"data_link_post.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    post_urls = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "with open(\"komentar.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx, post_url in enumerate(post_urls):\n",
    "        driver.get(post_url)\n",
    "        time.sleep(5)\n",
    "        f.write(f\"üìå Post {idx+1} - URL: {post_url}\\n\")\n",
    "\n",
    "        # Tambahkan ini sebelum loop komentar dimulai\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Di dalam loop saat mengambil komentar:\n",
    "        try:\n",
    "            # Tunggu maksimal 10 detik sampai elemen <h1> caption muncul\n",
    "            h1_element = wait.until(EC.presence_of_element_located((\n",
    "                By.XPATH,\n",
    "                '//article//ul//div[1]//li//div//div//div[2]//div[1]//h1'\n",
    "            )))\n",
    "\n",
    "            html_caption = h1_element.get_attribute(\"innerHTML\")\n",
    "\n",
    "            # Parsing HTML caption\n",
    "            soup = BeautifulSoup(html_caption, \"html.parser\")\n",
    "\n",
    "            for br in soup.find_all(\"br\"):\n",
    "                br.replace_with(\"\\n\")\n",
    "\n",
    "            caption_text = soup.get_text(strip=True)\n",
    "\n",
    "            f.write(f\"üìÑ Caption: {caption_text}\\n\")\n",
    "        except Exception as e:\n",
    "            f.write(\"üìÑ Caption: Tidak ditemukan\\n\")\n",
    "\n",
    "        # Klik semua \"Lihat semua komentar\" jika ada\n",
    "        while True:\n",
    "            try:\n",
    "                load_more = driver.find_element(By.XPATH, \"//button[contains(text(),'Lihat semua') or contains(text(),'View all')]\")\n",
    "                driver.execute_script(\"arguments[0].click();\", load_more)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        # Tunggu agar komentar dimuat\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        # Ambil semua elemen komentar\n",
    "        comment_items = driver.find_elements(By.XPATH, '//ul[contains(@class, \"\")]/div/li')\n",
    "\n",
    "        comment_counter = 1\n",
    "        for item in comment_items:\n",
    "            try:\n",
    "                username_elem = item.find_element(By.XPATH, './/h3//a')\n",
    "                username = username_elem.get_attribute('href').split('/')[-2]\n",
    "\n",
    "                comment_elem = item.find_element(By.XPATH, './/span[@dir=\"auto\"]')\n",
    "                comment_text = comment_elem.text.strip()\n",
    "\n",
    "                if comment_text:\n",
    "                    f.write(f\"Komentar {comment_counter}: @{username}: {comment_text}\\n\")\n",
    "                    comment_counter += 1\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "         # Tambahan: Likes dan tanggal upload\n",
    "        try:\n",
    "            like_elem = driver.find_element(By.XPATH, '//section[2]//div//span/a/span/span')\n",
    "            like_count = like_elem.text.strip()\n",
    "            f.write(f\"‚ù§Ô∏è Likes: {like_count}\\n\")\n",
    "        except Exception as e:\n",
    "            f.write(\"‚ù§Ô∏è Likes: Tidak ditemukan\\n\")\n",
    "\n",
    "        try:\n",
    "            time_elem = driver.find_element(By.XPATH, '//time')\n",
    "            upload_date = time_elem.get_attribute('datetime')\n",
    "            f.write(f\"üìÖ Tanggal Upload: {upload_date}\\n\")\n",
    "        except Exception as e:\n",
    "            f.write(\"üìÖ Tanggal Upload: Tidak ditemukan\\n\")\n",
    "\n",
    "        f.write(\"---\\n\\n\")\n",
    "\n",
    "print(\"‚úÖ Semua komentar berhasil disimpan di komentar.txt\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12978b",
   "metadata": {},
   "source": [
    "# PROCESSING SCRAPE COMMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dddfd6f",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73eeeb0",
   "metadata": {},
   "source": [
    "Choose One ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472555d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('komentar.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575938d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Buka dua file dan baca isinya\n",
    "# with open('komentar_skiphop.txt', 'r', encoding='utf-8') as f1, \\\n",
    "#      open('komentar_yumboxindonesia.txt', 'r', encoding='utf-8') as f2:\n",
    "#     content1 = f1.read()\n",
    "#     content2 = f2.read()\n",
    "\n",
    "# # Gabungkan isi kedua file\n",
    "# content = content1 + '\\n' + content2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f300d",
   "metadata": {},
   "source": [
    "f-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e896f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = content.split('---')\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in posts:\n",
    "    if not post.strip():\n",
    "        continue\n",
    "\n",
    "    full_text = post.strip().replace('\\n', ' ')\n",
    "\n",
    "    # URL\n",
    "    url_match = re.search(r'URL:\\s*(https://www\\.instagram\\.com/\\S+)', full_text)\n",
    "    url = url_match.group(1) if url_match else ''\n",
    "\n",
    "    # Caption\n",
    "    caption_match = re.search(r'üìÑ Caption:\\s*(.*?)(?=‚ù§Ô∏è Likes:|üìÖ Tanggal Upload:)', full_text)\n",
    "    caption = caption_match.group(1).strip() if caption_match else ''\n",
    "\n",
    "    # Likes\n",
    "    likes_match = re.search(r'‚ù§Ô∏è Likes:\\s*(\\d+)', full_text)\n",
    "    likes = likes_match.group(1) if likes_match else '0'\n",
    "\n",
    "    # Date\n",
    "    date_match = re.search(r'üìÖ Tanggal Upload:\\s*([\\d\\-T:.Z]+)', full_text)\n",
    "    date = date_match.group(1) if date_match else ''\n",
    "\n",
    "    # Comments\n",
    "    comment_lines = re.findall(r'Komentar \\d+:\\s*(.+?)\\s*(?=Komentar \\d+:|‚ù§Ô∏è Likes:|üìÖ Tanggal Upload:|$)', full_text)\n",
    "    comment_count = len(comment_lines)\n",
    "\n",
    "    # Format output\n",
    "    if comment_lines:\n",
    "        for i, comment in enumerate(comment_lines):\n",
    "            user_match = re.match(r'(@[^:]+):', comment)\n",
    "            comment_user = user_match.group(1) if user_match else ''\n",
    "            comment_text = comment.split(\":\", 1)[1].strip() if \":\" in comment else comment\n",
    "            if i == 0:\n",
    "                data.append([url, caption, date, likes, comment_count, comment_text, comment_user])\n",
    "            else:\n",
    "                data.append([''] * 5 + [comment_text, comment_user])\n",
    "    else:\n",
    "        data.append([url, caption, date, likes, comment_count, '', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat DataFrame\n",
    "df_comment = pd.DataFrame(data, columns=[\"url\", \"caption\", \"dates\", \"likes count\", \"comment count\", \"comments\", \"comment_user\"])\n",
    "df_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38072c",
   "metadata": {},
   "source": [
    "## Apify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912db9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fc0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file.csv')\n",
    "\n",
    "# Mengganti nama kolom\n",
    "df_comment = df.rename(columns={\n",
    "    'ownerUsername': 'username',\n",
    "    'text': 'comments'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6bd932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3bc70",
   "metadata": {},
   "source": [
    "# DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d0656c",
   "metadata": {},
   "source": [
    "## Data Cleaning & Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "94d17213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ef617ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c9cf9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        u\"\\u2600-\\u26FF\"\n",
    "        u\"\\u2700-\\u27BF\"\n",
    "        u\"\\uFE0F\"\n",
    "        u\"\\U0001F900-\\U0001F9FF\"\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_meanings = {\n",
    "    \"‚ù§Ô∏è\": \"love it\",\n",
    "    \"etc\": \"etc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9bf3417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji_only(text):\n",
    "    \"\"\"Cek apakah teks hanya berisi emoji (dan spasi)\"\"\"\n",
    "    text_no_space = text.replace(\" \", \"\")\n",
    "    return all(char in emoji_meanings for char in text_no_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corrections = {\n",
    "    \"jastip\": \"jasa titip\",\n",
    "    \"etc\": \"etc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "432dda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_trailing_chars(word):\n",
    "    return re.sub(r'([^0-9])\\1+', r'\\1', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72a17bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_comment(comment):\n",
    "#     if not isinstance(comment, str) or comment.strip() == '':\n",
    "#         return None\n",
    "\n",
    "#     # Hapus emoji\n",
    "#     comment = remove_emojis(comment)\n",
    "\n",
    "#     # Hapus karakter aneh/non-ASCII\n",
    "#     comment = re.sub(r'[^\\x00-\\x7F]+', ' ', comment)\n",
    "    \n",
    "#     comment = comment.lower()\n",
    "\n",
    "#     # Hapus huruf double di akhir kata\n",
    "#     words = comment.split()\n",
    "#     cleaned_words = [remove_repeated_trailing_chars(word) for word in words]\n",
    "#     cleaned = ' '.join(cleaned_words)\n",
    "\n",
    "#     # Koreksi kata tidak baku\n",
    "#     for wrong, correct in word_corrections.items():\n",
    "#         cleaned = re.sub(rf'\\b{wrong}\\b', correct, cleaned)\n",
    "\n",
    "#     # Lowercase sebelum translate\n",
    "#     cleaned = cleaned.lower()\n",
    "\n",
    "#     # Translate\n",
    "#     try:\n",
    "#         translated = translator.translate(cleaned.strip(), src='id', dest='en').text\n",
    "#     except:\n",
    "#         translated = cleaned.strip()\n",
    "\n",
    "#     return translated if translated.strip() != '' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "072fce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(comment):\n",
    "    if not isinstance(comment, str) or comment.strip() == '':\n",
    "        return None\n",
    "\n",
    "    comment = comment.strip()\n",
    "\n",
    "    # 1. Cek jika komentar hanya berisi emoji yang dikenal\n",
    "    if is_emoji_only(comment):\n",
    "        words = [emoji_meanings[char] for char in comment if char in emoji_meanings]\n",
    "        return ' '.join(words) if words else None\n",
    "\n",
    "    # 2. Proses normal (jika bukan hanya emoji)\n",
    "    # Hapus emoji\n",
    "    comment = remove_emojis(comment)\n",
    "\n",
    "    # Hapus karakter aneh/non-ASCII\n",
    "    comment = re.sub(r'[^\\x00-\\x7F]+', ' ', comment)\n",
    "    \n",
    "    comment = comment.lower()\n",
    "\n",
    "    # Hapus huruf double di akhir kata\n",
    "    words = comment.split()\n",
    "    cleaned_words = [remove_repeated_trailing_chars(word) for word in words]\n",
    "    cleaned = ' '.join(cleaned_words)\n",
    "\n",
    "    # Koreksi kata tidak baku\n",
    "    for wrong, correct in word_corrections.items():\n",
    "        cleaned = re.sub(rf'\\b{wrong}\\b', correct, cleaned)\n",
    "\n",
    "    # Translate\n",
    "    try:\n",
    "        translated = translator.translate(cleaned.strip(), src='id', dest='en').text\n",
    "    except:\n",
    "        translated = cleaned.strip()\n",
    "\n",
    "    return translated if translated.strip() != '' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ambil kolom comments\n",
    "sa_comments = df_comment['comments'].copy()\n",
    "\n",
    "# Step 2: Hapus kosong\n",
    "sa_comments = sa_comments.replace('', np.nan).dropna().reset_index(drop=True)\n",
    "\n",
    "# Step 3: Konversi ke string\n",
    "sa_comments = sa_comments.astype(str)\n",
    "\n",
    "# Step 4: Jalankan fungsi cleaning\n",
    "sa_comments = sa_comments.apply(clean_comment)\n",
    "\n",
    "# Step 5: Hapus hasil kosong setelah cleaning\n",
    "sa_comments = sa_comments.replace('', np.nan).dropna().reset_index(drop=True)\n",
    "\n",
    "# Step 6: Lakukan lowercase SETELAH translate\n",
    "sa_comments = sa_comments.apply(lambda x: x.lower())\n",
    "\n",
    "# Step 6.5: Hapus komentar yang hanya terdiri dari 1-2 huruf\n",
    "sa_comments = sa_comments[sa_comments.apply(lambda x: len(x.strip()) > 2)].reset_index(drop=True)\n",
    "\n",
    "# Step 7 (Opsional): Simpan ke CSV\n",
    "sa_comments.to_csv(\"sa_comments.csv\", sep=\";\", index=False, encoding='utf-8')\n",
    "\n",
    "# Preview hasil\n",
    "sa_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa8db1",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3a81d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk\n",
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1eb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "972039c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_label(text):\n",
    "    score = sia.polarity_scores(text)['compound']\n",
    "    if score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d4366869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat DataFrame baru\n",
    "sa_df = pd.DataFrame({'comment': sa_comments})\n",
    "\n",
    "# Tambahkan kolom 'sentiment'\n",
    "sa_df['sentiment'] = sa_df['comment'].apply(get_sentiment_label)\n",
    "\n",
    "# Preview hasil\n",
    "# print(sa_df.head())\n",
    "# sa_df\n",
    "sa_df.to_csv(\"sa_mooij_df.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52928ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung jumlah komentar per label sentimen\n",
    "sentiment_counts = sa_df['sentiment'].value_counts().reindex(['positive', 'neutral', 'negative'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='Set2')\n",
    "\n",
    "plt.title(\"Jumlah Komentar Berdasarkan Sentimen\", fontsize=14)\n",
    "plt.xlabel(\"Label Sentimen\")\n",
    "plt.ylabel(\"Jumlah Komentar\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Gabungkan semua komentar menjadi satu string\n",
    "all_text = \" \".join(sa_df['comment'])\n",
    "\n",
    "# Pisahkan kata dan hitung frekuensinya\n",
    "words = all_text.split()\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# Ubah ke DataFrame dan urutkan\n",
    "word_freq_df = pd.DataFrame(word_freq.items(), columns=['Word', 'Frequency'])\n",
    "word_freq_df = word_freq_df.sort_values(by='Frequency', ascending=False).reset_index(drop=True)\n",
    "word_freq_df.to_csv(\"word_freq_df_mooij.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Buat WordCloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "\n",
    "# Tampilkan WordCloud\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud Semua Komentar\", fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
